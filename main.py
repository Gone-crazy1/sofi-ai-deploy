from flask import Flask, request, jsonify, url_for, render_template
from flask_cors import CORS
import os, requests, hashlib, logging, json, asyncio, tempfile, re
from datetime import datetime
from supabase import create_client
import openai
from openai import OpenAI
from typing import Dict, Optional, Any
import time
from utils.bank_api import BankAPI
from utils.secure_transfer_handler import SecureTransferHandler
from utils.balance_helper import get_user_balance as get_balance_secure, check_virtual_account as check_virtual_account_secure
# Paystack Integration - Banking Partner
from paystack import get_paystack_service
from paystack.paystack_webhook import handle_paystack_webhook
# OpenAI Assistant Integration
from assistant import get_assistant
from dotenv import load_dotenv
import random
from PIL import Image
from io import BytesIO
from pydub import AudioSegment
from pydub.utils import which
from utils.memory import save_memory, list_memories, save_chat_message, get_chat_history
from utils.conversation_state import conversation_state
from utils.nigerian_expressions import enhance_nigerian_message, get_response_guidance
from utils.prompt_schemas import get_image_prompt, validate_image_result
from unittest.mock import MagicMock

# Load environment variables from .env file
load_dotenv()

# Environment configuration
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_ROLE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PAYSTACK_SECRET_KEY = os.getenv("PAYSTACK_SECRET_KEY")
PAYSTACK_WEBHOOK_SECRET = os.getenv("PAYSTACK_WEBHOOK_SECRET")

# Initialize Flask app
app = Flask(__name__)
CORS(app)

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize Supabase and OpenAI clients
supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY) if SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY else None
openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# Check for required environment variables
required_vars = [
    "TELEGRAM_BOT_TOKEN",
    "SUPABASE_URL", 
    "SUPABASE_SERVICE_ROLE_KEY",
    "OPENAI_API_KEY",
    "PAYSTACK_SECRET_KEY"
]

missing_vars = [var for var in required_vars if not os.getenv(var)]
if missing_vars:
    logger.warning(f"‚ö†Ô∏è Missing environment variables: {missing_vars}")

if not PAYSTACK_WEBHOOK_SECRET:
    logger.warning("PAYSTACK_WEBHOOK_SECRET not set - webhook verification disabled")

# Initialize admin chat IDs
ADMIN_CHAT_IDS = os.getenv("ADMIN_CHAT_IDS")
if ADMIN_CHAT_IDS:
    admin_ids = [int(id.strip()) for id in ADMIN_CHAT_IDS.split(",") if id.strip().isdigit()]
    logger.info(f"‚úÖ Loaded {len(admin_ids)} admin IDs")
else:
    admin_ids = []
    logger.warning("‚ö†Ô∏è ADMIN_CHAT_IDS not configured! Admin commands will be disabled.")
    logger.warning("‚ö†Ô∏è No admin IDs loaded from environment!")

# Import admin handler AFTER environment loading
from utils.admin_command_handler import AdminCommandHandler
admin_handler = AdminCommandHandler()

# Import user onboarding system
from utils.user_onboarding import SofiUserOnboarding
onboarding_service = SofiUserOnboarding()

# Set the path to the ffmpeg executable for pydub
AudioSegment.converter = which("ffmpeg")

def send_reply(chat_id, message, reply_markup=None):
    """Send reply message to Telegram chat with optional inline keyboard"""
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": chat_id, 
        "text": message,
        "parse_mode": "Markdown"
    }
    
    if reply_markup:
        payload["reply_markup"] = reply_markup
        
    response = requests.post(url, json=payload)
    return response.json() if response.status_code == 200 else None

def generate_pos_style_receipt(sender_name, amount, recipient_name, recipient_account, recipient_bank, balance, transaction_id):
    """Generate a POS-style receipt for a transaction."""
    receipt = f"""
=================================
      SOFI AI TRANSFER RECEIPT
=================================
Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
Transaction ID: {transaction_id}
---------------------------------
Sender: {sender_name}
Amount: ‚Ç¶{amount:,.2f}
Recipient: {recipient_name}
Account: {recipient_account}
Bank: {recipient_bank}
---------------------------------
New Balance: ‚Ç¶{balance:,.2f}
=================================
    Thanks for using Sofi AI!
=================================
"""
    return receipt

def detect_intent(message):
    """Enhanced intent detector using OpenAI API with chatgpt-4o-latest and Nigerian expressions support"""
    try:
        # Step 1: Enhance message with Nigerian expressions understanding
        enhanced_analysis = enhance_nigerian_message(message)
        enhanced_message = enhanced_analysis["enhanced_message"]
        
        # Log the enhancement for debugging
        if enhanced_analysis["contains_nigerian_expressions"]:
            logger.info(f"üá≥üá¨ Enhanced Nigerian expression: '{message}' -> '{enhanced_message}'")
        
        # Use the intent parser system prompt for better transfer detection
        from nlp.intent_parser import system_prompt
        
        # Create enhanced system prompt that includes Nigerian context
        enhanced_system_prompt = system_prompt + """
        
IMPORTANT NIGERIAN CONTEXT:
- The user may use Nigerian English, Pidgin, or local expressions
- Common patterns: "send 5k give my guy" = send 5000 naira to my friend
- "My account don empty" = my account is empty
- "Abeg" = please, "sharp sharp" = immediately, "now now" = right now
- "kudi/ego/owo" = money, "guy/padi/paddy" = friend
- Always interpret enhanced/translated messages while maintaining cultural context        """
        
        response = openai_client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {"role": "system", "content": enhanced_system_prompt},
                {"role": "user", "content": f"Original: {message}\nEnhanced: {enhanced_message}"}
            ],
            temperature=0.3
        )
        
        # Parse the response as JSON
        try:
            # Handle mock responses in tests
            if isinstance(response, MagicMock):
                content = response.choices[0]['message']['content']
            else:
                # OpenAI v1.x syntax
                content = response.choices[0].message.content
                # Log the raw response in non-test environment
                with open("api_logs.txt", "a") as log_file:
                    log_file.write(f"Message: {message}\nResponse: {response}\n\n")
            
            content = content.strip()
            parsed = json.loads(content)
            
            return parsed
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse intent JSON: {content}")
            return {"intent": "general", "details": {}}
            
    except Exception as e:
        logger.error(f"Error detecting intent: {e}")
        return {"intent": "general", "details": {}}

async def get_user_balance(chat_id):
    """Get user's current balance from virtual account using secure method"""
    try:
        return await get_balance_secure(str(chat_id))
    except Exception as e:
        logger.error(f"Error getting user balance: {e}")
        return 0.0

async def check_virtual_account(chat_id):
    """Check if user has a virtual account using secure method"""
    try:
        return await check_virtual_account_secure(str(chat_id))
    except Exception as e:
        logger.error(f"Error checking virtual account: {e}")
        return None

async def generate_ai_reply(chat_id: str, message: str):
    """Generate AI reply with conversation context and Nigerian expressions support"""
    # Ensure message is always a string
    if isinstance(message, bytes):
        message = message.decode('utf-8', errors='ignore')
    elif not isinstance(message, str):
        message = str(message)
    
    # Step 1: Enhance message with Nigerian expressions understanding
    enhanced_analysis = enhance_nigerian_message(message)
    enhanced_message = enhanced_analysis["enhanced_message"]
    response_guidance = get_response_guidance(enhanced_analysis)
    
    # Log enhancement for debugging
    if enhanced_analysis["contains_nigerian_expressions"]:
        logger.info(f"üá≥üá¨ AI Reply Enhancement: '{message}' -> '{enhanced_message}'")
        logger.info(f"üìù Response Guidance: {response_guidance}")
        
    # Concise system prompt
    system_prompt = """You are Sofi AI, a Nigerian banking assistant. Be brief and helpful.

Key features: transfers, airtime, data, balance checks.
New users: Direct to https://sofi-ai-trio.onrender.com/onboarding
Keep responses short (2-3 lines max). Use Nigerian style but stay professional."""

    try:
        # Check if user has a virtual account
        virtual_account = await check_virtual_account(chat_id)
        
        # First check if this is about account creation or account status
        if not virtual_account and any(keyword in message.lower() for keyword in ['account', 'create', 'setup', 'register', 'onboard']):
            return """üè¶ Welcome to Sofi AI! 

To get started with your account:
üëâ Click here: https://sofi-ai-trio.onrender.com/onboarding

This will create your virtual account and get you ready for transfers, airtime, and more! üöÄ"""
        
        # Get conversation history for context
        chat_history = get_chat_history(chat_id, limit=5)
        context_messages = []
        
        for msg in chat_history:
            role = "user" if msg.get('is_user', True) else "assistant"  
            content = msg.get('message', '')
            if content and len(content.strip()) > 0:
                context_messages.append({"role": role, "content": content})
        
        # Add current message
        context_messages.append({"role": "user", "content": enhanced_message})
        
        # Add system message with response guidance
        full_system_prompt = system_prompt
        if response_guidance:
            full_system_prompt += f"\n\nResponse guidance for this message: {response_guidance}"
        
        messages = [{"role": "system", "content": full_system_prompt}] + context_messages[-6:]
        
        # Get AI response
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=150,
            temperature=0.7
        )
        
        ai_reply = response.choices[0].message.content.strip()
        
        # Save the conversation
        save_chat_message(chat_id, message, is_user=True)
        save_chat_message(chat_id, ai_reply, is_user=False)
        
        return ai_reply
        
    except Exception as e:
        logger.error(f"Error generating AI reply: {e}")
        return "I'm having trouble processing your request right now. Please try again in a moment."

# Import components after environment setup
try:
    from utils.fee_calculator import get_fee_calculator
    logger.info("‚úÖ Fee calculator loaded successfully")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Fee calculator issue: {e}")

# Flask Routes
@app.route("/health")
def health_check():
    """Health check endpoint"""
    return jsonify({"status": "healthy", "timestamp": datetime.now().isoformat()})

@app.route("/webhook", methods=["POST"])
async def webhook_incoming():
    """Handle incoming Telegram messages and callback queries"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({"error": "Invalid update payload", "response": None}), 400
        
        # Handle callback queries (inline keyboard responses)
        if "callback_query" in data:
            callback_query = data["callback_query"]
            callback_data = callback_query.get("data", "")
            chat_id = callback_query["from"]["id"]
            
            logger.info(f"üìû Callback received: {callback_data} from {chat_id}")
            
            # Handle PIN entry system callbacks
            if callback_data.startswith("pin_"):
                from utils.pin_entry_system import pin_manager
                response = await pin_manager.handle_callback(callback_query)
                
                # Answer the callback query to remove loading state
                await answer_callback_query(callback_query["id"])
                
                if response and response.get("message"):
                    await send_reply(chat_id, response["message"])
                
                return jsonify({"status": "callback_handled", "response": response})
            
            # Handle other callback queries
            return jsonify({"status": "callback_received", "data": callback_data})
        
        # Handle regular messages
        if "message" not in data:
            return jsonify({"error": "Invalid message payload", "response": None}), 400
        
        message_data = data["message"]
        chat_id = message_data["chat"]["id"]
        
        # Handle different message types
        if "text" in message_data:
            text = message_data["text"]
            logger.info(f"üì® Text message from {chat_id}: {text}")
            
            # Check for admin commands first
            if str(chat_id) in [str(aid) for aid in admin_ids]:
                admin_response = await admin_handler.handle_admin_command(chat_id, text)
                if admin_response:
                    await send_reply(chat_id, admin_response)
                    return jsonify({"status": "admin_command_handled"})
            
            # Regular message processing
            response = await process_message(chat_id, text)
            if response:
                await send_reply(chat_id, response)
            
        elif "photo" in message_data:
            # Handle photo messages
            logger.info(f"üì∑ Photo message from {chat_id}")
            response = await process_photo_message(chat_id, message_data)
            if response:
                await send_reply(chat_id, response)
        
        elif "voice" in message_data:
            # Handle voice messages  
            logger.info(f"üé§ Voice message from {chat_id}")
            response = await process_voice_message(chat_id, message_data)
            if response:
                await send_reply(chat_id, response)
        
        return jsonify({"status": "message_processed"})
        
    except Exception as e:
        logger.error(f"‚ùå Webhook error: {str(e)}")
        return jsonify({"error": str(e)}), 500

async def process_message(chat_id: int, text: str) -> str:
    """Process incoming text message and return response"""
    try:
        # Detect intent using OpenAI
        intent_result = detect_intent(text)
        intent = intent_result.get("intent", "general")
        details = intent_result.get("details", {})
        
        logger.info(f"üéØ Intent detected: {intent} with details: {details}")
        
        # Handle different intents
        if intent == "transfer":
            # Use the assistant for money transfers (with proper PIN flow)
            assistant = get_assistant()
            response = await assistant.process_message(str(chat_id), text)
            return response
            
        elif intent == "balance":
            # Quick balance check
            balance = await get_user_balance(chat_id)
            return f"üí∞ Your current balance is ‚Ç¶{balance:,.2f}"
            
        elif intent == "account_creation":
            # Direct to onboarding
            return """üè¶ Welcome to Sofi AI! 

To create your account:
üëâ Click here: https://sofi-ai-trio.onrender.com/onboarding

This will set up your virtual account instantly! üöÄ"""
            
        else:
            # General conversation - use AI assistant
            return await generate_ai_reply(str(chat_id), text)
            
    except Exception as e:
        logger.error(f"‚ùå Error processing message: {str(e)}")
        return "I'm having trouble right now. Please try again in a moment."

async def process_photo_message(chat_id: int, message_data: dict) -> str:
    """Process photo messages"""
    try:
        # Get the largest photo
        photos = message_data["photo"]
        largest_photo = max(photos, key=lambda x: x["file_size"])
        file_id = largest_photo["file_id"]
        
        # Download the image
        image_data = download_file(file_id)
        
        if not image_data:
            return "‚ùå Sorry, I couldn't download your image. Please try again."
        
        # Process the image with OpenAI Vision
        import base64
        base64_image = base64.b64encode(image_data).decode('utf-8')
        
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "What's in this image? Be brief and helpful."},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]
                }
            ],
            max_tokens=150
        )
        
        return f"üì∑ I can see: {response.choices[0].message.content}"
        
    except Exception as e:
        logger.error(f"‚ùå Error processing photo: {str(e)}")
        return "‚ùå Sorry, I had trouble processing your image."

async def process_voice_message(chat_id: int, message_data: dict) -> str:
    """Process voice messages"""
    try:
        voice = message_data["voice"]
        file_id = voice["file_id"]
        
        # Download the voice file
        voice_data = download_file(file_id)
        
        if not voice_data:
            return "‚ùå Sorry, I couldn't download your voice message."
        
        # Save to temporary file for processing
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as temp_file:
            temp_file.write(voice_data)
            temp_file_path = temp_file.name
        
        try:
            # Convert to wav for transcription
            audio = AudioSegment.from_ogg(temp_file_path)
            wav_path = temp_file_path.replace(".ogg", ".wav")
            audio.export(wav_path, format="wav")
            
            # Transcribe with OpenAI Whisper
            with open(wav_path, "rb") as audio_file:
                transcript = openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file
                )
            
            text = transcript.text
            logger.info(f"üé§ Transcribed: {text}")
            
            # Process the transcribed text
            response = await process_message(chat_id, text)
            return f"üé§ I heard: \"{text}\"\n\n{response}"
            
        finally:
            # Clean up temp files
            try:
                os.unlink(temp_file_path)
                if os.path.exists(wav_path):
                    os.unlink(wav_path)
            except:
                pass
        
    except Exception as e:
        logger.error(f"‚ùå Error processing voice: {str(e)}")
        return "‚ùå Sorry, I had trouble processing your voice message."

def download_file(file_id):
    """Download file from Telegram"""
    try:
        # Get file info
        file_info_response = requests.get(f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/getFile?file_id={file_id}")
        file_info = file_info_response.json()
        
        if not file_info.get("ok"):
            return None
        
        file_path = file_info["result"]["file_path"]
        
        # Download file
        file_response = requests.get(f"https://api.telegram.org/file/bot{TELEGRAM_BOT_TOKEN}/{file_path}")
        
        return file_response.content if file_response.status_code == 200 else None
        
    except Exception as e:
        logger.error(f"‚ùå Error downloading file: {str(e)}")
        return None

async def answer_callback_query(callback_query_id: str, text: str = ""):
    """Answer a callback query to remove loading state"""
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/answerCallbackQuery"
    payload = {
        "callback_query_id": callback_query_id,
        "text": text
    }
    
    try:
        response = requests.post(url, json=payload)
        return response.json() if response.status_code == 200 else None
    except Exception as e:
        logger.error(f"‚ùå Error answering callback query: {str(e)}")
        return None

@app.route("/")
def index():
    """Basic index route"""
    return jsonify({
        "message": "Sofi AI Backend Running",
        "status": "healthy",
        "features": [
            "Money transfers with PIN security",
            "Balance checks", 
            "Airtime & data purchases",
            "Nigerian expression support",
            "Voice & image processing",
            "Admin commands"
        ],
        "endpoints": ["/health", "/webhook"]
    })

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=False)
